# Getting Structured LLM Output


1. [Introduction](#1)
1. [Text Generation](#2)
    1. [Text Generation Parameters](#3)
       1. [Max Token Generation Length](#4)
       2. [Temperature](#5)
       3. [Top P](#6)
       4. [Stop or Finish Sequence](#7)
    2. [Text models with Bedrock](#8)
       1. [How to use batch inference vs. On-demand](#9)

 

<a name="1"></a>
## Introduction


<a name="10"></a>
References <a href="https://www.deeplearning.ai/short-courses/getting-structured-llm-output/">Getting Structured LLM Output - Deeplearning.ai</a>
